{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import importlib\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import data_utils\n",
    "import model_utils\n",
    "import train_utils\n",
    "import evaluation\n",
    "import submission\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(model_utils)\n",
    "importlib.reload(train_utils)\n",
    "importlib.reload(evaluation)\n",
    "importlib.reload(submission)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_dict = {\"train\": \"./data/train_real.csv\", \n",
    "             \"val_text\": \"./hw2_utterance_dev.txt\",\n",
    "             \"val_label\": \"./hw2_tags_dev.txt\",\n",
    "             \"test_text\": \"./hw2_utterance_test.txt\",\n",
    "             \"holdout\": \"./data/holdout.csv\"}\n",
    "train_data, val_data, test_data, info = data_utils.prep_all_data(\n",
    "    file_dict, batch_size=1, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 151.5429, Val Loss: 88.4779, Val f1 0.600, epoch time: 2.7s\n",
      "Epoch: 1, LR: 0.001, Train Loss: 47.2335, Val Loss: 76.9151, Val f1 0.683, epoch time: 2.8s\n",
      "Epoch: 2, LR: 0.001, Train Loss: 22.1414, Val Loss: 62.3697, Val f1 0.738, epoch time: 2.8s\n",
      "Epoch: 3, LR: 0.001, Train Loss: 11.0858, Val Loss: 65.0368, Val f1 0.757, epoch time: 2.8s\n",
      "Epoch: 4, LR: 0.001, Train Loss: 5.6552, Val Loss: 67.8574, Val f1 0.768, epoch time: 2.8s\n",
      "Epoch: 5, LR: 0.001, Train Loss: 3.2823, Val Loss: 64.2119, Val f1 0.761, epoch time: 2.8s\n",
      "Epoch: 6, LR: 0.001, Train Loss: 2.2067, Val Loss: 67.2561, Val f1 0.758, epoch time: 2.7s\n",
      "Epoch: 7, LR: 0.001, Train Loss: 1.4807, Val Loss: 72.0254, Val f1 0.757, epoch time: 2.8s\n",
      "Epoch: 8, LR: 0.001, Train Loss: 1.1186, Val Loss: 70.5598, Val f1 0.767, epoch time: 2.7s\n",
      "Epoch: 9, LR: 0.001, Train Loss: 0.8599, Val Loss: 69.2148, Val f1 0.775, epoch time: 2.8s\n",
      "Epoch: 10, LR: 0.001, Train Loss: 0.7789, Val Loss: 70.5466, Val f1 0.775, epoch time: 2.8s\n",
      "Epoch: 11, LR: 0.001, Train Loss: 0.5299, Val Loss: 71.6069, Val f1 0.776, epoch time: 2.7s\n",
      "Epoch: 12, LR: 0.001, Train Loss: 0.4297, Val Loss: 72.2857, Val f1 0.779, epoch time: 2.6s\n",
      "Epoch: 13, LR: 0.0001, Train Loss: 0.3490, Val Loss: 73.1253, Val f1 0.777, epoch time: 2.8s\n",
      "Epoch: 14, LR: 0.0001, Train Loss: 0.2951, Val Loss: 73.5248, Val f1 0.777, epoch time: 2.7s\n",
      "Epoch: 15, LR: 0.0001, Train Loss: 0.2829, Val Loss: 73.7926, Val f1 0.776, epoch time: 2.8s\n",
      "Epoch: 16, LR: 0.0001, Train Loss: 0.2761, Val Loss: 73.9856, Val f1 0.776, epoch time: 2.7s\n",
      "Epoch: 17, LR: 0.0001, Train Loss: 0.2712, Val Loss: 74.1284, Val f1 0.773, epoch time: 2.7s\n",
      "Epoch: 18, LR: 0.0001, Train Loss: 0.2670, Val Loss: 74.2458, Val f1 0.773, epoch time: 2.8s\n",
      "Epoch: 19, LR: 0.0001, Train Loss: 0.2631, Val Loss: 74.3569, Val f1 0.773, epoch time: 2.8s\n",
      "Epoch: 20, LR: 0.0001, Train Loss: 0.2592, Val Loss: 74.4633, Val f1 0.773, epoch time: 2.8s\n",
      "Epoch: 21, LR: 0.0001, Train Loss: 0.2554, Val Loss: 74.5765, Val f1 0.773, epoch time: 2.8s\n",
      "Epoch: 22, LR: 0.0001, Train Loss: 0.2516, Val Loss: 74.6901, Val f1 0.773, epoch time: 2.7s\n",
      "Epoch: 23, LR: 0.0001, Train Loss: 0.2477, Val Loss: 74.8006, Val f1 0.773, epoch time: 2.8s\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.GRU(info, direction=2).cuda()\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-3, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_GRU = result[\"trained_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 1e-05, Train Loss: 6.9148, Val Loss: 5.9229, Val f1 0.130, epoch time: 123.4s\n",
      "Epoch: 1, LR: 1e-05, Train Loss: 4.6921, Val Loss: 5.0505, Val f1 0.164, epoch time: 124.3s\n",
      "Epoch: 2, LR: 1e-05, Train Loss: 3.6306, Val Loss: 4.2201, Val f1 0.353, epoch time: 125.2s\n",
      "Epoch: 3, LR: 1e-05, Train Loss: 2.8912, Val Loss: 3.7763, Val f1 0.482, epoch time: 124.3s\n",
      "Epoch: 4, LR: 1e-05, Train Loss: 2.4406, Val Loss: 3.5336, Val f1 0.582, epoch time: 124.0s\n",
      "Epoch: 5, LR: 1e-05, Train Loss: 2.0189, Val Loss: 3.7444, Val f1 0.467, epoch time: 124.5s\n",
      "Epoch: 6, LR: 1e-05, Train Loss: 1.7790, Val Loss: 3.4687, Val f1 0.584, epoch time: 124.7s\n",
      "Epoch: 7, LR: 1e-05, Train Loss: 1.5135, Val Loss: 3.1951, Val f1 0.673, epoch time: 125.6s\n",
      "Epoch: 8, LR: 1e-05, Train Loss: 1.2945, Val Loss: 3.2953, Val f1 0.705, epoch time: 123.3s\n",
      "Epoch: 9, LR: 1e-05, Train Loss: 1.2025, Val Loss: 3.0144, Val f1 0.689, epoch time: 125.7s\n",
      "Epoch: 10, LR: 1e-05, Train Loss: 1.0526, Val Loss: 2.5923, Val f1 0.769, epoch time: 126.8s\n",
      "Epoch: 11, LR: 1e-05, Train Loss: 0.9744, Val Loss: 2.5488, Val f1 0.782, epoch time: 125.9s\n",
      "Epoch: 12, LR: 1e-05, Train Loss: 0.9161, Val Loss: 2.6895, Val f1 0.770, epoch time: 125.0s\n",
      "Epoch: 13, LR: 1e-05, Train Loss: 0.7921, Val Loss: 2.8428, Val f1 0.785, epoch time: 127.5s\n",
      "Epoch: 14, LR: 1e-05, Train Loss: 0.7397, Val Loss: 2.6151, Val f1 0.773, epoch time: 123.6s\n",
      "Epoch: 15, LR: 1e-05, Train Loss: 0.7112, Val Loss: 2.6628, Val f1 0.786, epoch time: 124.0s\n",
      "Epoch: 16, LR: 1e-05, Train Loss: 0.6429, Val Loss: 2.9924, Val f1 0.740, epoch time: 123.8s\n",
      "Epoch: 17, LR: 1.0000000000000002e-06, Train Loss: 0.6303, Val Loss: 2.7265, Val f1 0.799, epoch time: 123.8s\n",
      "Epoch: 18, LR: 1.0000000000000002e-06, Train Loss: 0.4266, Val Loss: 2.4986, Val f1 0.815, epoch time: 123.4s\n",
      "Epoch: 19, LR: 1.0000000000000002e-06, Train Loss: 0.3552, Val Loss: 2.4746, Val f1 0.818, epoch time: 123.7s\n",
      "Epoch: 20, LR: 1.0000000000000002e-06, Train Loss: 0.3227, Val Loss: 2.5260, Val f1 0.818, epoch time: 124.6s\n",
      "Epoch: 21, LR: 1.0000000000000002e-06, Train Loss: 0.3021, Val Loss: 2.4890, Val f1 0.812, epoch time: 123.9s\n",
      "Epoch: 22, LR: 1.0000000000000002e-06, Train Loss: 0.2834, Val Loss: 2.5001, Val f1 0.819, epoch time: 123.6s\n",
      "Epoch: 23, LR: 1.0000000000000002e-06, Train Loss: 0.2721, Val Loss: 2.5067, Val f1 0.826, epoch time: 123.7s\n",
      "Epoch: 24, LR: 1.0000000000000002e-06, Train Loss: 0.2621, Val Loss: 2.5581, Val f1 0.834, epoch time: 124.1s\n",
      "Epoch: 25, LR: 1.0000000000000002e-07, Train Loss: 0.2535, Val Loss: 2.5293, Val f1 0.819, epoch time: 124.0s\n",
      "Epoch: 26, LR: 1.0000000000000002e-07, Train Loss: 0.2390, Val Loss: 2.5433, Val f1 0.819, epoch time: 124.2s\n",
      "Epoch: 27, LR: 1.0000000000000002e-07, Train Loss: 0.2371, Val Loss: 2.5484, Val f1 0.820, epoch time: 123.9s\n",
      "Epoch: 28, LR: 1.0000000000000002e-07, Train Loss: 0.2354, Val Loss: 2.5381, Val f1 0.820, epoch time: 124.1s\n",
      "Epoch: 29, LR: 1.0000000000000002e-07, Train Loss: 0.2323, Val Loss: 2.5481, Val f1 0.821, epoch time: 123.9s\n",
      "Epoch: 30, LR: 1.0000000000000002e-07, Train Loss: 0.2332, Val Loss: 2.5460, Val f1 0.822, epoch time: 124.2s\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "importlib.reload(train_utils)\n",
    "importlib.reload(data_utils)\n",
    "\n",
    "train_data, val_data, info = data_utils.prep_all_data(\n",
    "    file_dict, batch_size=1)\n",
    "m = model_utils.BertSlot(info).cuda()\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(result[\"trained_model\"].state_dict(), \"./data/model_checkpoints/bertSlot_Feb28.mdl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_bert = result[\"trained_model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 4.8025, Val Loss: 6.3148, Val f1 0.616, epoch time: 4.1s\n",
      "Epoch: 1, LR: 0.001, Train Loss: 1.9605, Val Loss: 5.9936, Val f1 0.594, epoch time: 4.1s\n",
      "Epoch: 2, LR: 0.001, Train Loss: 1.5960, Val Loss: 5.8579, Val f1 0.616, epoch time: 4.1s\n",
      "Epoch: 3, LR: 0.001, Train Loss: 1.4659, Val Loss: 5.4492, Val f1 0.607, epoch time: 4.0s\n",
      "Epoch: 4, LR: 0.001, Train Loss: 1.4150, Val Loss: 5.4308, Val f1 0.586, epoch time: 4.0s\n",
      "Epoch: 5, LR: 0.001, Train Loss: 1.3831, Val Loss: 5.2612, Val f1 0.600, epoch time: 4.0s\n",
      "Epoch: 6, LR: 0.001, Train Loss: 1.3727, Val Loss: 5.1516, Val f1 0.618, epoch time: 4.0s\n",
      "Epoch: 7, LR: 0.001, Train Loss: 1.3678, Val Loss: 5.1899, Val f1 0.607, epoch time: 3.9s\n",
      "Epoch: 8, LR: 0.001, Train Loss: 1.3534, Val Loss: 5.2619, Val f1 0.592, epoch time: 4.1s\n",
      "Epoch: 9, LR: 0.001, Train Loss: 1.3527, Val Loss: 5.1682, Val f1 0.554, epoch time: 4.0s\n",
      "Epoch: 10, LR: 0.001, Train Loss: 1.3490, Val Loss: 5.2218, Val f1 0.552, epoch time: 3.9s\n",
      "Epoch: 11, LR: 0.001, Train Loss: 1.3548, Val Loss: 5.3439, Val f1 0.538, epoch time: 4.1s\n",
      "Epoch: 12, LR: 0.0001, Train Loss: 1.3418, Val Loss: 5.4185, Val f1 0.520, epoch time: 4.0s\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.BaseModel(info, pretrain=\"ft\").cuda()\n",
    "train_data, val_data, info = data_utils.prep_all_data(file_dict, batch_size=1)\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-3, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 3.8290, Val Loss: 4.4245, Val f1 0.532, epoch time: 3.9s\n",
      "Epoch: 1, LR: 0.001, Train Loss: 1.9041, Val Loss: 4.6375, Val f1 0.546, epoch time: 4.0s\n",
      "Epoch: 2, LR: 0.001, Train Loss: 1.5889, Val Loss: 4.8041, Val f1 0.550, epoch time: 4.1s\n",
      "Epoch: 3, LR: 0.001, Train Loss: 1.4834, Val Loss: 5.0831, Val f1 0.550, epoch time: 4.0s\n",
      "Epoch: 4, LR: 0.001, Train Loss: 1.4441, Val Loss: 5.1472, Val f1 0.542, epoch time: 4.0s\n",
      "Epoch: 5, LR: 0.001, Train Loss: 1.4089, Val Loss: 5.3307, Val f1 0.530, epoch time: 4.1s\n",
      "Epoch: 6, LR: 0.0001, Train Loss: 1.4039, Val Loss: 5.3643, Val f1 0.542, epoch time: 4.0s\n",
      "Epoch: 7, LR: 0.0001, Train Loss: 1.2760, Val Loss: 5.3755, Val f1 0.545, epoch time: 4.0s\n",
      "Epoch: 8, LR: 0.0001, Train Loss: 1.2476, Val Loss: 5.4066, Val f1 0.539, epoch time: 4.0s\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.BaseModel(info, pretrain=\"glove\").cuda()\n",
    "train_data, val_data, info = data_utils.prep_all_data(file_dict, batch_size=1)\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-3, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 5.5819, Val Loss: 4.1666, Val f1 0.521, epoch time: 4.0s\n",
      "Epoch: 1, LR: 0.001, Train Loss: 2.6193, Val Loss: 3.7894, Val f1 0.578, epoch time: 4.1s\n",
      "Epoch: 2, LR: 0.001, Train Loss: 2.0214, Val Loss: 3.7392, Val f1 0.589, epoch time: 4.0s\n",
      "Epoch: 3, LR: 0.001, Train Loss: 1.7922, Val Loss: 3.8118, Val f1 0.590, epoch time: 4.0s\n",
      "Epoch: 4, LR: 0.001, Train Loss: 1.6759, Val Loss: 4.0622, Val f1 0.541, epoch time: 4.0s\n",
      "Epoch: 5, LR: 0.001, Train Loss: 1.6106, Val Loss: 3.9454, Val f1 0.524, epoch time: 3.6s\n",
      "Epoch: 6, LR: 0.001, Train Loss: 1.6115, Val Loss: 4.1069, Val f1 0.528, epoch time: 3.8s\n",
      "Epoch: 7, LR: 0.001, Train Loss: 1.6057, Val Loss: 4.3533, Val f1 0.485, epoch time: 3.6s\n",
      "Epoch: 8, LR: 0.0001, Train Loss: 1.5804, Val Loss: 4.3187, Val f1 0.510, epoch time: 3.9s\n",
      "Epoch: 9, LR: 0.0001, Train Loss: 1.3332, Val Loss: 4.1779, Val f1 0.532, epoch time: 3.7s\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.BaseModel(info, pretrain=False).cuda()\n",
    "train_data, val_data, info = data_utils.prep_all_data(file_dict, batch_size=1)\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-3, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 5.6728, Val Loss: 4.4029, Val f1 0.514, epoch time: 4.0s\n",
      "Epoch: 1, LR: 0.001, Train Loss: 2.6445, Val Loss: 3.8269, Val f1 0.569, epoch time: 3.9s\n",
      "Epoch: 2, LR: 0.001, Train Loss: 2.0626, Val Loss: 3.8600, Val f1 0.547, epoch time: 4.0s\n",
      "Epoch: 3, LR: 0.001, Train Loss: 1.8022, Val Loss: 3.9125, Val f1 0.581, epoch time: 4.0s\n",
      "Epoch: 4, LR: 0.001, Train Loss: 1.6839, Val Loss: 4.0605, Val f1 0.578, epoch time: 3.9s\n",
      "Epoch: 5, LR: 0.001, Train Loss: 1.6443, Val Loss: 4.2622, Val f1 0.554, epoch time: 3.1s\n",
      "Epoch: 6, LR: 0.001, Train Loss: 1.6232, Val Loss: 4.3333, Val f1 0.526, epoch time: 3.7s\n",
      "Epoch: 7, LR: 0.0001, Train Loss: 1.5871, Val Loss: 4.3168, Val f1 0.573, epoch time: 3.6s\n",
      "Epoch: 8, LR: 0.0001, Train Loss: 1.3460, Val Loss: 4.2309, Val f1 0.567, epoch time: 3.6s\n",
      "Epoch: 9, LR: 0.0001, Train Loss: 1.2810, Val Loss: 4.2417, Val f1 0.578, epoch time: 3.6s\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.BaseModel(info).cuda()\n",
    "train_data, val_data, info = data_utils.prep_all_data(file_dict, batch_size=1)\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-3, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.588520765304565"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"total_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 414.4476, Val Loss: 226.1604, Val f1 0.261, epoch time: 1.5s\n",
      "Epoch: 1, LR: 0.001, Train Loss: 211.1787, Val Loss: 153.8800, Val f1 0.411, epoch time: 1.5s\n",
      "Epoch: 2, LR: 0.001, Train Loss: 145.3856, Val Loss: 123.8750, Val f1 0.461, epoch time: 1.4s\n",
      "Epoch: 3, LR: 0.001, Train Loss: 113.9929, Val Loss: 108.7808, Val f1 0.506, epoch time: 1.4s\n",
      "Epoch: 4, LR: 0.001, Train Loss: 95.3859, Val Loss: 100.2948, Val f1 0.534, epoch time: 1.4s\n",
      "Epoch: 5, LR: 0.001, Train Loss: 82.7822, Val Loss: 94.9902, Val f1 0.546, epoch time: 1.4s\n",
      "Epoch: 6, LR: 0.001, Train Loss: 73.6048, Val Loss: 91.5024, Val f1 0.564, epoch time: 1.4s\n",
      "Epoch: 7, LR: 0.001, Train Loss: 66.6497, Val Loss: 89.1499, Val f1 0.563, epoch time: 1.4s\n",
      "Epoch: 8, LR: 0.001, Train Loss: 61.2569, Val Loss: 87.5647, Val f1 0.567, epoch time: 1.4s\n",
      "Epoch: 9, LR: 0.001, Train Loss: 57.0154, Val Loss: 86.5397, Val f1 0.569, epoch time: 1.4s\n",
      "Epoch: 10, LR: 0.001, Train Loss: 53.6381, Val Loss: 85.9299, Val f1 0.572, epoch time: 1.4s\n",
      "Epoch: 11, LR: 0.001, Train Loss: 50.9288, Val Loss: 85.6216, Val f1 0.572, epoch time: 1.4s\n",
      "Epoch: 12, LR: 0.001, Train Loss: 48.7514, Val Loss: 85.5281, Val f1 0.572, epoch time: 1.4s\n",
      "Epoch: 13, LR: 0.001, Train Loss: 47.0047, Val Loss: 85.5840, Val f1 0.572, epoch time: 1.4s\n",
      "Epoch: 14, LR: 0.001, Train Loss: 45.6075, Val Loss: 85.7403, Val f1 0.573, epoch time: 1.4s\n",
      "Epoch: 15, LR: 0.001, Train Loss: 44.4917, Val Loss: 85.9624, Val f1 0.579, epoch time: 1.4s\n",
      "Epoch: 16, LR: 0.001, Train Loss: 43.6008, Val Loss: 86.2274, Val f1 0.579, epoch time: 1.4s\n",
      "Epoch: 17, LR: 0.001, Train Loss: 42.8892, Val Loss: 86.5208, Val f1 0.582, epoch time: 1.4s\n",
      "Epoch: 18, LR: 0.001, Train Loss: 42.3201, Val Loss: 86.8335, Val f1 0.582, epoch time: 1.4s\n",
      "Epoch: 19, LR: 0.001, Train Loss: 41.8640, Val Loss: 87.1594, Val f1 0.582, epoch time: 1.4s\n",
      "Epoch: 20, LR: 0.001, Train Loss: 41.4971, Val Loss: 87.4938, Val f1 0.582, epoch time: 1.4s\n",
      "Epoch: 21, LR: 0.001, Train Loss: 41.2005, Val Loss: 87.8326, Val f1 0.584, epoch time: 1.4s\n",
      "Epoch: 22, LR: 0.001, Train Loss: 40.9592, Val Loss: 88.1723, Val f1 0.584, epoch time: 1.4s\n",
      "Epoch: 23, LR: 0.0001, Train Loss: 40.7612, Val Loss: 88.5097, Val f1 0.584, epoch time: 1.4s\n",
      "Epoch: 24, LR: 0.0001, Train Loss: 39.7375, Val Loss: 86.8218, Val f1 0.578, epoch time: 1.4s\n",
      "Epoch: 25, LR: 0.0001, Train Loss: 37.9822, Val Loss: 86.6991, Val f1 0.575, epoch time: 1.4s\n",
      "Epoch: 26, LR: 0.0001, Train Loss: 37.6219, Val Loss: 86.7167, Val f1 0.572, epoch time: 1.4s\n",
      "Epoch: 27, LR: 0.0001, Train Loss: 37.4854, Val Loss: 86.7627, Val f1 0.570, epoch time: 1.4s\n",
      "Epoch: 28, LR: 0.0001, Train Loss: 37.4105, Val Loss: 86.8111, Val f1 0.570, epoch time: 1.4s\n",
      "Epoch: 29, LR: 0.0001, Train Loss: 37.3620, Val Loss: 86.8574, Val f1 0.570, epoch time: 1.4s\n",
      "Epoch: 30, LR: 0.0001, Train Loss: 37.3263, Val Loss: 86.9015, Val f1 0.570, epoch time: 1.4s\n",
      "Epoch: 31, LR: 0.0001, Train Loss: 37.2975, Val Loss: 86.9443, Val f1 0.570, epoch time: 1.4s\n",
      "Epoch: 32, LR: 0.0001, Train Loss: 37.2727, Val Loss: 86.9862, Val f1 0.570, epoch time: 1.4s\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.BaseModel(info).cuda()\n",
    "train_data, val_data, info = data_utils.prep_all_data(file_dict, batch_size=-1)\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-3, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.02327919006348"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"total_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.GRU(info, direction=1).cuda()\n",
    "train_data, val_data, info = data_utils.prep_all_data(file_dict, batch_size=1)\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-3, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.14653182029724"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"total_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 193.9474, Val Loss: 114.9780, Val f1 0.382, epoch time: 2.1s\n",
      "Epoch: 1, LR: 0.001, Train Loss: 75.5452, Val Loss: 83.8583, Val f1 0.617, epoch time: 2.1s\n",
      "Epoch: 2, LR: 0.001, Train Loss: 43.8587, Val Loss: 68.0680, Val f1 0.698, epoch time: 2.1s\n",
      "Epoch: 3, LR: 0.001, Train Loss: 28.7550, Val Loss: 58.0142, Val f1 0.708, epoch time: 2.1s\n",
      "Epoch: 4, LR: 0.001, Train Loss: 19.8479, Val Loss: 55.5259, Val f1 0.721, epoch time: 2.1s\n",
      "Epoch: 5, LR: 0.001, Train Loss: 14.6029, Val Loss: 56.5672, Val f1 0.726, epoch time: 2.1s\n",
      "Epoch: 6, LR: 0.001, Train Loss: 11.5257, Val Loss: 58.4251, Val f1 0.726, epoch time: 2.1s\n",
      "Epoch: 7, LR: 0.001, Train Loss: 9.6457, Val Loss: 58.4262, Val f1 0.729, epoch time: 2.1s\n",
      "Epoch: 8, LR: 0.001, Train Loss: 8.2930, Val Loss: 57.4351, Val f1 0.733, epoch time: 2.1s\n",
      "Epoch: 9, LR: 0.001, Train Loss: 7.0162, Val Loss: 57.2999, Val f1 0.738, epoch time: 2.1s\n",
      "Epoch: 10, LR: 0.001, Train Loss: 5.8338, Val Loss: 58.0442, Val f1 0.746, epoch time: 2.1s\n",
      "Epoch: 11, LR: 0.001, Train Loss: 5.1128, Val Loss: 59.9215, Val f1 0.742, epoch time: 2.1s\n",
      "Epoch: 12, LR: 0.001, Train Loss: 4.6764, Val Loss: 61.8429, Val f1 0.736, epoch time: 2.0s\n",
      "Epoch: 13, LR: 0.001, Train Loss: 4.3604, Val Loss: 63.8557, Val f1 0.734, epoch time: 2.1s\n",
      "Epoch: 14, LR: 0.001, Train Loss: 4.1369, Val Loss: 65.0994, Val f1 0.740, epoch time: 2.1s\n",
      "Epoch: 15, LR: 0.0001, Train Loss: 3.9684, Val Loss: 66.2836, Val f1 0.730, epoch time: 2.1s\n",
      "Epoch: 16, LR: 0.0001, Train Loss: 4.0547, Val Loss: 63.9236, Val f1 0.740, epoch time: 2.1s\n",
      "Epoch: 17, LR: 0.0001, Train Loss: 3.2879, Val Loss: 63.8983, Val f1 0.741, epoch time: 2.1s\n",
      "Epoch: 18, LR: 0.0001, Train Loss: 3.1941, Val Loss: 63.8716, Val f1 0.740, epoch time: 2.1s\n",
      "Epoch: 19, LR: 0.0001, Train Loss: 3.1221, Val Loss: 63.8996, Val f1 0.740, epoch time: 2.1s\n",
      "Epoch: 20, LR: 0.0001, Train Loss: 3.0743, Val Loss: 63.9520, Val f1 0.741, epoch time: 2.1s\n",
      "Epoch: 21, LR: 0.0001, Train Loss: 3.0359, Val Loss: 64.0302, Val f1 0.741, epoch time: 2.0s\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.GRU(info, direction=1).cuda()\n",
    "train_data, val_data, info = data_utils.prep_all_data(file_dict, batch_size=-1)\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-3, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.34501576423645"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"total_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 2.3658, Val Loss: 2.0394, Val f1 0.753, epoch time: 20.6s\n",
      "Epoch: 1, LR: 0.001, Train Loss: 0.4229, Val Loss: 2.1754, Val f1 0.770, epoch time: 22.8s\n",
      "Epoch: 2, LR: 0.001, Train Loss: 0.2173, Val Loss: 2.4627, Val f1 0.790, epoch time: 22.7s\n",
      "Epoch: 3, LR: 0.001, Train Loss: 0.1122, Val Loss: 2.6050, Val f1 0.791, epoch time: 22.6s\n",
      "Epoch: 4, LR: 0.001, Train Loss: 0.0813, Val Loss: 2.8167, Val f1 0.778, epoch time: 23.2s\n",
      "Epoch: 5, LR: 0.001, Train Loss: 0.0774, Val Loss: 3.1432, Val f1 0.762, epoch time: 23.1s\n",
      "Epoch: 6, LR: 0.0001, Train Loss: 0.0470, Val Loss: 3.1717, Val f1 0.778, epoch time: 23.4s\n",
      "Epoch: 7, LR: 0.0001, Train Loss: 0.0304, Val Loss: 3.1086, Val f1 0.785, epoch time: 23.0s\n",
      "Epoch: 8, LR: 0.0001, Train Loss: 0.0099, Val Loss: 3.1131, Val f1 0.787, epoch time: 23.4s\n",
      "Epoch: 9, LR: 0.0001, Train Loss: 0.0082, Val Loss: 3.1147, Val f1 0.787, epoch time: 23.3s\n",
      "232.24305272102356\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.GRU(info, direction=2).cuda()\n",
    "train_data, val_data, info = data_utils.prep_all_data(file_dict, batch_size=1)\n",
    "result = train_utils.train(train_data, val_data, m, lr=1e-3, patience=5)\n",
    "print(result[\"total_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, LR: 0.001, Train Loss: 2.4104, Val Loss: 2.6255, Val f1 0.714\n",
      "Epoch: 1, LR: 0.001, Train Loss: 0.4522, Val Loss: 2.1465, Val f1 0.764\n",
      "Epoch: 2, LR: 0.001, Train Loss: 0.1908, Val Loss: 2.1976, Val f1 0.787\n",
      "Epoch: 3, LR: 0.001, Train Loss: 0.1224, Val Loss: 2.3299, Val f1 0.791\n",
      "Epoch: 4, LR: 0.001, Train Loss: 0.0878, Val Loss: 2.7668, Val f1 0.786\n",
      "Epoch: 5, LR: 0.001, Train Loss: 0.0662, Val Loss: 2.8125, Val f1 0.805\n",
      "Epoch: 6, LR: 0.001, Train Loss: 0.0486, Val Loss: 2.8417, Val f1 0.808\n",
      "Epoch: 7, LR: 0.001, Train Loss: 0.0381, Val Loss: 3.0598, Val f1 0.793\n",
      "Epoch: 8, LR: 0.001, Train Loss: 0.0446, Val Loss: 3.0771, Val f1 0.799\n",
      "Epoch: 9, LR: 0.001, Train Loss: 0.0297, Val Loss: 3.2020, Val f1 0.805\n",
      "Epoch: 10, LR: 0.001, Train Loss: 0.0285, Val Loss: 3.3087, Val f1 0.796\n",
      "Epoch: 11, LR: 0.001, Train Loss: 0.0511, Val Loss: 3.7601, Val f1 0.774\n",
      "Epoch: 12, LR: 0.0001, Train Loss: 0.0183, Val Loss: 4.0560, Val f1 0.782\n",
      "Epoch: 13, LR: 0.0001, Train Loss: 0.0187, Val Loss: 4.0025, Val f1 0.786\n",
      "Epoch: 14, LR: 0.0001, Train Loss: 0.0069, Val Loss: 4.0040, Val f1 0.785\n",
      "Epoch: 15, LR: 0.0001, Train Loss: 0.0036, Val Loss: 4.0120, Val f1 0.785\n",
      "Epoch: 16, LR: 0.0001, Train Loss: 0.0031, Val Loss: 4.0455, Val f1 0.788\n",
      "Epoch: 17, LR: 0.0001, Train Loss: 0.0027, Val Loss: 4.0951, Val f1 0.785\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(model_utils)\n",
    "m = model_utils.GRU(info, direction=2).cuda()\n",
    "result = train_utils.train(train_data, val_data, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(result[\"trained_model\"], \"./data/model_checkpoints/biGRU_Feb23.mdl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction file saved to: prediction.txt\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submission)\n",
    "submission.get_submission(model=m_bert, data=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
